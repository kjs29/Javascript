# ASCII table

![image](https://github.com/kjs29/Javascript/assets/96529477/573ea341-ccf6-4a61-9161-23616140ea25)



```js
// Binary to base 10
console.log(Number(0b1010))
console.log(Number(0b0011))

// Binary to hexadecimal
console.log(Number(0b1010).toString(16))
console.log(Number(0b0011).toString(16))

// Hexadecimal to base 10
console.log(parseInt('0xa1',16))
console.log(Number(0xff))

// Hexadecimal to binary
console.log(0xa1.toString(2))
console.log(0xff.toString(2))

// Base 10 to binary
console.log((8).toString(2))
console.log((24).toString(2))
console.log((255).toString(2))

// Base 10 to hexadecimal
console.log((8).toString(16))
console.log((24).toString(16))
console.log((255).toString(16))

// Base 10 to ASCII
console.log(String.fromCharCode(65))
console.log(String.fromCharCode(66))
console.log(String.fromCharCode(97))
console.log(String.fromCharCode(98))

// Hexadecimal to ASCII
console.log(String.fromCharCode(parseInt('0x41',16)))
console.log(String.fromCharCode(parseInt('0x42',16)))
console.log(String.fromCharCode(parseInt('0x61',16)))
console.log(String.fromCharCode(parseInt('0x62',16)))

// Binary to ASCII
console.log(String.fromCharCode(0b01000001))
console.log(String.fromCharCode(0b01000001))
console.log(String.fromCharCode(0b01000010))
console.log(String.fromCharCode(0b01100001))
console.log(String.fromCharCode(0b01100010))

```

# To convert from ASCII code to 8-bit binary

```js
const asciiTo8bit = str => {
  let answer = "";
  for (let i =0;i<str.length;i++) {
    let binary = str.charCodeAt(i).toString(2)
    binary = binary.padStart(8, '0')
    answer += binary;
  }
  return answer;
};

console.log(asciiTo8bit('123'));
// 001100010011001000110011

console.log(asciiTo8bit('ABC'));
// 010000010100001001000011

console.log(asciiTo8bit('Hello, world!'));
// 01001000011001010110110001101100011011110010110000100000011101110110111101110010011011000110010000100001
```

# charCodeAt()

Notice that `charCodeAt()` was used. It was used to convert to unicode.

For example, `A` has unicode of 65.

```js
let string = 'Apple';
console.log(string.charCodeAt(0));    //65
```

# toString()

In the example above, 

notice that `toString()` was used.

We already covered that `charCodeAt()` has value of 65, so

```js
(65).toString(2);   // convert 65 to 2-base number(binary)
```

### One thing to keep in mind:

I put `(65).toString(2)` instead of `65.toString(2)` because there can be decimal places after 65, so we need to put parenthesis around the number.

# padStart()

Notice that `padStart()` was used. It was used because ascii code converts to 8-bit binary,

which means that there are 2^8 = 256 possible combinations, and each place has either `0` or `1`.

So Let's say, if ASCII code is 'A', then it is 65 in decimal number, and 65 is `1000001`.

`1000001` has 7 placements, and it should be 8 digit places, so `padStart()` helps to put `0`s to make sure it is <strong>8 digit number</strong>.

<em>Example of `padStart().</em>

```js
let cardNumbers = '1049283749304751';
let lastFourDigits = cardNumbers.slice(-4);
console.log(lastFourDigits.padStart(cardNumbers.length,'*'))   //************4751
```
